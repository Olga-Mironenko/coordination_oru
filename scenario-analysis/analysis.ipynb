{
 "cells": [
  {
   "cell_type": "code",
   "id": "aa538ed1f5b724f8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "from typing import List, Tuple\n",
    "\n",
    "import IPython.display\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.patches import Rectangle"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9151475a74002447",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "id": "88f7de86491a529d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "RUNDIRS = '../logs/rundirs'\n",
    "\n",
    "# BASENAME_CSV = 'sorted-20241128_210446' \n",
    "# BASENAME_CSV = '20241203_133243/sorted' \n",
    "BASENAME_CSV = '20241203_170129_all600/sorted' \n",
    "I_MAP = 1\n",
    "BASENAME_CSV_LINEARIZATIONS = '20241212_114658_lin_abcd/sorted' "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e71e4db69c390fd1",
   "metadata": {},
   "source": [
    "DIRECTORY_IMAGES = f'images/{BASENAME_CSV.split(\"/\")[0]}'\n",
    "os.makedirs(DIRECTORY_IMAGES, exist_ok=True)\n",
    "\n",
    "df_orig = pd.read_csv(f'{RUNDIRS}/{BASENAME_CSV}.csv')\n",
    "df_orig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a727282a50efa04",
   "metadata": {},
   "source": [
    "def normalize_linearization(lin):\n",
    "    if lin is None:\n",
    "        return None\n",
    "    return tuple(\n",
    "        np.interp(\n",
    "            np.linspace(0, 1, 100),\n",
    "            np.linspace(0, 1, len(lin)), \n",
    "            lin\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to combine tuples into a tuple of small tuples\n",
    "def combine_tuples(cols, row):\n",
    "    # Extract the relevant columns from the row\n",
    "    selected = [row[col] for col in cols]\n",
    "    # Replace None with tuples of Nones based on the size of the first non-None tuple\n",
    "    tuples = [col \n",
    "              if col is not None else \n",
    "              (None,) * len(next(c for c in selected if c is not None)) \n",
    "              for col in selected]\n",
    "    # Combine using zip\n",
    "    return tuple(zip(*tuples))\n",
    "\n",
    "\n",
    "def normalize_df(df_orig):\n",
    "    df_id = df_orig['Scenario ID'].str.split(r'[;,] ', expand=True)\n",
    "    df_id.columns = ['filename', 'Coordination strategy', 'string_seed', 'string_probabilityForcingForHuman', 'heuristic']\n",
    "    df_id = pd.concat([\n",
    "        df_id,\n",
    "        df_id['filename'].str.extract(r'(?P<dir_map>[^/]+)/(?P<basename_scenario>[^/]+)[.]json$', expand=True),\n",
    "        df_id['filename'].str.extract(r'/scenario(?P<i_map>\\d+)-(?P<i_locations>\\d+)[.]json$', expand=True).astype(int),\n",
    "        df_id['string_probabilityForcingForHuman'].str.extract(r'^probabilityForcingForHuman (?P<probabilityForcingForHuman>[\\d.]+)$', expand=True).astype(float),\n",
    "    ], axis=1).rename(columns={'i_locations': 'Positions variant'})\n",
    "    df_id['filename_screenshot'] = \"../map-generator/generated-maps/\" + df_id['dir_map'] + '/screenshots/' + df_id['basename_scenario'] + '.png'\n",
    "    df_id['are_bridges'] = df_id['dir_map'].str.contains('with_bridges')\n",
    "    df_id['configuration'] = df_id[\n",
    "        ['i_map', 'are_bridges', 'Positions variant']].agg(\n",
    "        lambda r: f'map {r['i_map']}, {\"with\" if r['are_bridges'] else \"without\"} bridges, pos.var. {r['Positions variant']}', \n",
    "        axis=1\n",
    "    )\n",
    "    #df_id = df_id[df_id['i_map'] == I_MAP]\n",
    "    \n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df_id[['i_map', 'are_bridges', 'Positions variant', 'configuration', \n",
    "                   'Coordination strategy', 'probabilityForcingForHuman', 'filename_screenshot']],\n",
    "            df_orig\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    df.sort_values(\n",
    "        ['i_map', 'are_bridges', 'Positions variant', 'Vehicle ID'], \n",
    "        ascending=[True, False, True, True],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    postfix_nonnormalized = ' (non-normalized)'\n",
    "    col_lin_d = 'Linearization D'\n",
    "    pairs_lin_d: List[Tuple[int, str]] = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith('Linearization'):\n",
    "            series = df[col].apply(lambda x: None if pd.isna(x) else tuple(map(float, x.split())))\n",
    "            df[col] = series.apply(normalize_linearization)\n",
    "            col_nonnormalized = col + postfix_nonnormalized\n",
    "            df[col_nonnormalized] = series\n",
    "            if col.startswith(col_lin_d):\n",
    "                id_vehicle = int(col[len(col_lin_d):]) \n",
    "                pairs_lin_d.append((id_vehicle, col_nonnormalized))\n",
    "            \n",
    "    # Create new column\n",
    "    if pairs_lin_d:\n",
    "        cols_lin_d = [col for _, col in sorted(pairs_lin_d)]\n",
    "        df[col_lin_d + postfix_nonnormalized] = df.apply(lambda row: combine_tuples(cols_lin_d, row), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df_orig_norm = normalize_df(df_orig)\n",
    "configuration_to_filename_screenshot = {row['configuration']: row['filename_screenshot'] for _, row in df_orig_norm.iterrows()}\n",
    "df_orig_norm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "676c03ffff93aa5b",
   "metadata": {},
   "source": [
    "df_lin = None if BASENAME_CSV_LINEARIZATIONS is None else pd.read_csv(f'{RUNDIRS}/{BASENAME_CSV_LINEARIZATIONS}.csv')\n",
    "df_lin"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54c83a706cae72ca",
   "metadata": {},
   "source": [
    "df_lin_norm = None if df_lin is None else normalize_df(df_lin)\n",
    "df_lin_norm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb94e71a4b5f8aeb",
   "metadata": {},
   "source": [
    "def add_linearizations(df_orig_norm, df_lin_norm):\n",
    "    if df_lin_norm is None:\n",
    "        return df_orig_norm\n",
    "\n",
    "    # Get columns that start with 'Linearization'\n",
    "    linearization_cols = [col for col in df_lin_norm.columns if col.startswith('Linearization')]\n",
    "    assert linearization_cols\n",
    "    \n",
    "    # Specified keys for merging\n",
    "    keys = ['i_map', 'are_bridges', 'Positions variant', 'Vehicle ID']\n",
    "    \n",
    "    # Check if keys exist in both dataframes\n",
    "    missing_keys = [key for key in keys\n",
    "                    if key not in df_lin_norm.columns\n",
    "                    or key not in df_orig_norm.columns]\n",
    "    if missing_keys:\n",
    "        raise KeyError(f\"Missing key columns in either DataFrame: {missing_keys}\")\n",
    "    \n",
    "    # Perform an inner merge to ensure all data from df_lin is matched and not missing\n",
    "    merged_df = pd.merge(df_orig_norm, df_lin_norm[keys + linearization_cols], on=keys, how='inner')\n",
    "    \n",
    "    # Check if the merged DataFrame has any missing data from df_lin\n",
    "    #if merged_df[linearization_cols].isnull().any().any():\n",
    "    #    raise ValueError(\"Some linearization is missing in the merged DataFrame.\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "df_all = add_linearizations(df_orig_norm, df_lin_norm)\n",
    "df_all.to_csv('data/df_all.csv', index=False)\n",
    "df_all"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "980fd900d10ea283",
   "metadata": {},
   "source": [
    "# Filtering by `i_map`"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b2f52a2ae5c80a1",
   "metadata": {},
   "source": [
    "df_map = df_all[df_all['i_map'] == I_MAP]\n",
    "df_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ed4a5e4496ab680",
   "metadata": {},
   "source": [
    "def display_groups(groups):\n",
    "    for key, df in groups:\n",
    "        print(key)\n",
    "        IPython.display.display(df[['Is blocked']])\n",
    "\n",
    "groups_blocks = df_map[df_map['Vehicle type'] != 'HumanDrivenVehicle'].groupby(['configuration', 'are_bridges'], sort=False)\n",
    "#display_groups(groups_blocks)\n",
    "series_blocks = groups_blocks['Is blocked'].sum()\n",
    "series_blocks"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "index_blocked = series_blocks[series_blocks != 0].index\n",
    "index_nonblocked = series_blocks[series_blocks == 0].index\n",
    "index_nonblocked[~index_nonblocked.get_level_values('are_bridges')].get_level_values('configuration')"
   ],
   "id": "2bab01e915ca6450",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7496e90959b3417",
   "metadata": {},
   "source": [
    "# Main plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0b3ede6da09458b",
   "metadata": {},
   "source": [
    "def save_and_show(fig, basename):  # to avoid inlining large image data into the notebook file\n",
    "    filename = f'{DIRECTORY_IMAGES}/{basename}.png'\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "    # The `random` is because of https://stackoverflow.com/a/43640705.\n",
    "    IPython.display.display(IPython.display.HTML(f'<img src=\"{filename}?{random.random()}\" alt=\"{basename}\" />'))\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def same_value(series):\n",
    "    assert series.nunique(dropna=False) == 1, series\n",
    "    return series.iloc[0]\n",
    "    \n",
    "\n",
    "def make_misbehaviors(df_nonbaseline):\n",
    "    misbehaviors = []\n",
    "    \n",
    "    probabilityForcingForHuman = same_value(df_nonbaseline['probabilityForcingForHuman'])\n",
    "    if probabilityForcingForHuman > 0.0:\n",
    "        misbehaviors.append(f'violation of priorities ({\"random\" if probabilityForcingForHuman < 1.0 else \"constant\"})')\n",
    "        \n",
    "    isCanPassFirstActive = same_value(df_nonbaseline['isCanPassFirstActive'])\n",
    "    if isCanPassFirstActive.startswith('hum=true, '):\n",
    "        misbehaviors.append('can pass first')\n",
    "    elif isCanPassFirstActive.startswith('hum=false, '):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(isCanPassFirstActive)\n",
    "    \n",
    "    if 'probabilitySlowingDownForHuman' in df_nonbaseline.columns:\n",
    "        probabilitySlowingDownForHuman = float(same_value(df_nonbaseline['probabilitySlowingDownForHuman']))\n",
    "        if probabilitySlowingDownForHuman > 0.0:\n",
    "            misbehaviors.append(f'moving slowly ({\"random\" if probabilitySlowingDownForHuman < 1.0 else \"constant\"})')\n",
    "    \n",
    "    return misbehaviors\n",
    "\n",
    "\n",
    "def make_subplots(ncols):\n",
    "    return plt.subplots(1, ncols, figsize=(20, 6), sharey=True, squeeze=False)\n",
    "    \n",
    "\n",
    "def plot_title(df, *, title2):\n",
    "    positions = df.index.get_level_values('Positions variant').unique()\n",
    "    fig, axes = make_subplots(len(positions))\n",
    "    default_fig_width, default_fig_height = fig.get_size_inches()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = plt.figure(figsize=(default_fig_width, 1))\n",
    "    \n",
    "    misbehaviors = make_misbehaviors(df[df['Coordination strategy'] != 'baseline'])\n",
    "    title3 = 'Human (mis)behaviour actions: ' + ('none' if not misbehaviors else ', '.join(misbehaviors))    \n",
    "    \n",
    "    title = f'{title2}\\n{title3}'\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    title1 = '.title'\n",
    "    filename_png = save_and_show(fig, f'{title1}: {title2}')\n",
    "    \n",
    "    return filename_png\n",
    "    \n",
    "    \n",
    "class Formula:\n",
    "    def __init__(self, label, expression=None):\n",
    "        self.label = label\n",
    "        self.expression = expression if expression is not None else label\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.label.replace('`', '')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<Formula: {self.label!r}>'\n",
    "    \n",
    "    def apply(self, df):\n",
    "        if isinstance(self.expression, str):\n",
    "            return df.eval(self.expression)\n",
    "        return df.apply(self.expression, axis=1)\n",
    "    \n",
    "    \n",
    "def add_categorical_classes(ax, n):\n",
    "    \"\"\"\n",
    "    Add N classes to the x-axis with N-1 ticks in each class, excluding the class index.\n",
    "\n",
    "    Parameters:\n",
    "    ax (matplotlib.axes.Axes): The axis to modify.\n",
    "    n (int): The number of classes (vehicles).\n",
    "    \"\"\"\n",
    "    # Generate tick positions and labels for the primary x-axis\n",
    "    primary_ticks = []\n",
    "    primary_labels = []\n",
    "    for i in range(n):\n",
    "        start = i * (n - 1)\n",
    "        ticks = [k for k in range(n) if k != i]  # Exclude the class index\n",
    "        primary_ticks.extend(start + np.arange(len(ticks)))\n",
    "        primary_labels.extend([str(tick) for tick in ticks])\n",
    "\n",
    "    ax.set_xticks(primary_ticks)\n",
    "    ax.set_xticklabels(primary_labels)\n",
    "\n",
    "    # Add secondary x-axis for class annotations\n",
    "    sec = ax.secondary_xaxis(location=0)\n",
    "\n",
    "    # Define class boundaries and labels\n",
    "    class_centers = [(i * (n - 1) + (n - 2) / 2) for i in range(n)]\n",
    "    class_labels = [f\"\\n\\n{i}\" for i in range(n)]\n",
    "    sec.set_xticks(class_centers, labels=class_labels)\n",
    "    sec.tick_params('x', length=0)\n",
    "\n",
    "    # Add another secondary x-axis for boundaries between classes\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    class_boundaries = np.arange(-0.5, n * (n - 1), n - 1)\n",
    "    sec2.set_xticks(class_boundaries, labels=[])\n",
    "    sec2.tick_params('x', length=40, width=1.5)\n",
    "\n",
    "    # Adjust the axis limits\n",
    "    ax.set_xlim(-0.5, n * (n - 1) - 0.5)\n",
    "    \n",
    "    \n",
    "def plot_vertical_heatmap(ax, max_length, df, column):    \n",
    "    cells = df[column]\n",
    "    \n",
    "    is_normalized = not column.endswith(' (non-normalized)')\n",
    "\n",
    "    # Expand each list to have the same length\n",
    "    expanded_data = []\n",
    "    is_matrix = False\n",
    "    for cell in cells:\n",
    "        assert isinstance(cell, tuple)\n",
    "        assert cell\n",
    "        vectors: List[Tuple[float]] = []\n",
    "        if isinstance(cell[0], float):\n",
    "            vectors.append(cell)\n",
    "        else:\n",
    "            assert isinstance(cell[0], tuple)\n",
    "            is_matrix = True\n",
    "            for j in range(len(cell[0])):\n",
    "                vector = tuple(cell[i][j] for i in range(len(cell)))\n",
    "                assert vector\n",
    "                assert all(type(x) == type(vector[0]) for x in vector)\n",
    "                if vector[0] is not None:\n",
    "                    assert isinstance(vector[0], float)\n",
    "                    vectors.append(vector)\n",
    "        \n",
    "        for vector in vectors:\n",
    "            k_extra = max_length - len(cell)\n",
    "            if is_normalized:\n",
    "                assert k_extra == 0\n",
    "            expanded_data.append(vector + (np.nan,) * k_extra)\n",
    "\n",
    "    # Convert the expanded data to a 2D NumPy array\n",
    "    data_array = np.array(expanded_data)\n",
    "\n",
    "    # Transpose the data array to have heatmaps side-by-side (columns represent each row)\n",
    "    data_array_transposed = data_array.T\n",
    "\n",
    "    # Plot the heatmap - each column is a vertical slice now (grayscale, 0 is white, max is black)\n",
    "    im = ax.imshow(data_array_transposed, aspect='auto', cmap='gray_r', interpolation='nearest')\n",
    "\n",
    "    # Set labels for better readability\n",
    "    labels_ids = list(df.index.get_level_values(\"Vehicle ID\"))\n",
    "    if not is_matrix:\n",
    "        ax.set_xlabel('Vehicle ID')\n",
    "        ax.set_xticks(np.arange(len(df.index)))\n",
    "        ax.set_xticklabels(labels_ids)\n",
    "    else:\n",
    "        n_vehicles = len(labels_ids)\n",
    "        assert labels_ids == list(range(n_vehicles))\n",
    "        add_categorical_classes(ax, n_vehicles)\n",
    "        ax.set_xlabel('\\n\\nVehicle ID')\n",
    "    \n",
    "    if is_normalized:\n",
    "        ax.set_ylabel('Stage along the path')\n",
    "        y_ticks = np.linspace(0, max_length - 1, 5)  # Set 5 evenly spaced ticks from 0 to max_length - 1\n",
    "        ax.set_yticks(y_ticks)  # Apply these y-tick positions\n",
    "        ax.set_yticklabels([f'{int((tick / (max_length - 1)) * 100)}%' for tick in y_ticks])  # Label ticks from 0% to 100%\n",
    "    else:    \n",
    "        ax.set_ylabel('Meters of the path')\n",
    "        \n",
    "        # Generate mask for NaN values\n",
    "        nan_mask = np.isnan(data_array_transposed)\n",
    "        \n",
    "        # Adding rectangles around non-NaN regions for each column\n",
    "        for col in range(data_array_transposed.shape[1]):\n",
    "            nan_rows = np.where(nan_mask[:, col])[0]\n",
    "            \n",
    "            # Determine the start and end of non-NaN regions\n",
    "            if len(nan_rows) == 0:\n",
    "                # No NaN values in the column; entire column is non-NaN\n",
    "                start_row = 0\n",
    "                end_row = data_array_transposed.shape[0]\n",
    "            else:\n",
    "                # If there are NaNs, find the first occurrence\n",
    "                start_row = 0\n",
    "                end_row = nan_rows[0]\n",
    "            \n",
    "            # Draw rectangle around non-NaN values\n",
    "            rect = Rectangle((col - 0.5, start_row - 0.5), 1, end_row - start_row, edgecolor='black', facecolor='none', linewidth=2)\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    # Return the image object for colorbar usage\n",
    "    return im\n",
    "\n",
    "\n",
    "def plot_lin(df, *, title2, column):\n",
    "    #IPython.display.display(df)\n",
    "    \n",
    "    # Plot configuration\n",
    "    positions = df.index.get_level_values('Positions variant').unique()    \n",
    "    fig, axes = make_subplots(len(positions))\n",
    "    axes: list[list[Axes]]\n",
    "\n",
    "    # Find the maximum length of rows\n",
    "    max_length = max(\n",
    "        max(df.loc[position, column].apply(len))\n",
    "        for position in positions\n",
    "    )\n",
    "    \n",
    "    images = []\n",
    "    for i, position in enumerate(positions):\n",
    "        ax: Axes = axes[0][i]\n",
    "        df_pos = df.loc[position]\n",
    "        images.append(plot_vertical_heatmap(ax, max_length, df_pos, column=column))\n",
    "        ax.set_title(f'Position {position}')\n",
    "    \n",
    "    title1 = f'Paths segmentation based on CS density ({column})'\n",
    "    column2description = {\n",
    "        'Linearization': 'From the full simulation. Same as Linearization A.', \n",
    "        'Linearization A': 'From the short simulation. CS count: +1 for each CS.', \n",
    "        'Linearization B': \"From the short simulation. For each CS: +1 / other's path length.\", \n",
    "        'Linearization C': \"From the short simulation. For each CS: + CS length / other's path length.\", \n",
    "    }\n",
    "    description = column2description.get(column)\n",
    "    \n",
    "    title = title1\n",
    "    if description is not None:\n",
    "        title += f'\\n({description})'\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    \n",
    "    cax = fig.add_axes([0.85, 0.9, 0.1, 0.03])  # Adjust values to position the colorbar correctly\n",
    "    fig.colorbar(\n",
    "        images[0], cax=cax, label='Density',\n",
    "        orientation='horizontal', location='top',\n",
    "    )\n",
    "    \n",
    "    filename_png = save_and_show(fig, f'{title1}: {title2}')\n",
    "    \n",
    "    #print(id(df))\n",
    "    #IPython.display.display(df)\n",
    "    return filename_png, {}\n",
    "    \n",
    "    \n",
    "def plot_aut_hum(df, *, title2, dfs_y1, dfs_y2, mode):\n",
    "    #IPython.display.display(df)\n",
    "    \n",
    "    # Plot configuration\n",
    "    positions = df.index.get_level_values('Positions variant').unique()    \n",
    "    fig, axes = make_subplots(len(positions))\n",
    "    axes: list[list[Axes]]\n",
    "    bar_width = 0.4\n",
    "    \n",
    "    strategies = df.index.get_level_values('Coordination strategy').unique()    \n",
    "    strategy2label = {'baseline': 'baseline\\n(no human effect)', 'stops': 'stops (local)'}        \n",
    "\n",
    "    formulas_y2_aut = [Formula('`No. of collisions`'), Formula('`No. of near-misses`')]\n",
    "    colors_y2_aut = ['red', 'yellow']\n",
    "    \n",
    "    formulas_y2_hum = [Formula('`No. of violations`')] + formulas_y2_aut\n",
    "    colors_y2_hum = ['black'] + colors_y2_aut\n",
    "    \n",
    "    formulas_y2_cmp = [Formula(f'`{col}` / `No. of violations`', \n",
    "                               lambda row, _col=col: row[_col] / row['No. of violations'] if row['No. of violations'] > 0 else 0)\n",
    "                       for col in ('No. of collisions', 'No. of near-misses')]\n",
    "    colors_y2_cmp = ['red', 'yellow']\n",
    "    \n",
    "    if mode.startswith('aut_') or mode == 'hum':\n",
    "        if mode == 'aut_missions':\n",
    "            column_y1 = 'No. of completed missions'\n",
    "            color_y1 = 'tab:green'\n",
    "        else:\n",
    "            column_y1 = 'Total distance traveled (m)'\n",
    "            color_y1 = 'tab:blue'\n",
    "        \n",
    "        if mode.startswith('aut_'):\n",
    "            formulas_y2 = formulas_y2_aut\n",
    "            colors_y2 = colors_y2_aut\n",
    "            id_vehicle_max = df['Vehicle ID'].max()\n",
    "            title1 = f'Automated vehicles (summarised for AV1-AV{id_vehicle_max})' \n",
    "        else:\n",
    "            assert mode == 'hum'\n",
    "            formulas_y2 = formulas_y2_hum\n",
    "            colors_y2 = colors_y2_hum\n",
    "            title1 = 'Human-driven vehicle'\n",
    "            \n",
    "    elif mode == 'cmp':\n",
    "        column_y1 = None\n",
    "        color_y1 = None\n",
    "        \n",
    "        formulas_y2 = formulas_y2_cmp\n",
    "        colors_y2 = colors_y2_cmp\n",
    "        title1 = 'Collisions rate'\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "    \n",
    "    # Get the global max values for consistent y-axis scaling\n",
    "    if column_y1 is not None:\n",
    "        y1_max = max(dfx[column_y1].max() for dfx in dfs_y1)\n",
    "        y1_lim = y1_max * 1.1\n",
    "    y2_maxes = [formula.apply(dfx).max()\n",
    "                for dfx in dfs_y2\n",
    "                for formula in (formulas_y2 if mode == 'cmp' else set(formulas_y2_aut + formulas_y2_hum))]\n",
    "    y2_max = max(y2_maxes)\n",
    "    y2_lim = y2_max * 1.1\n",
    "    if mode == 'cmp':\n",
    "        y2_lim = 2.0\n",
    "    \n",
    "    pos2metstrat2value = {}\n",
    "    \n",
    "    # Iterate through each Positions variant\n",
    "    for i, position in enumerate(positions):\n",
    "        ax: Axes = axes[0][i]\n",
    "        df_pos = df.loc[position]\n",
    "        pos2metstrat2value[position] = metstrat2value = {}\n",
    "        \n",
    "        def add_to_metstrat2value(metric, series):\n",
    "            for strategy, value in series.items():\n",
    "                metstrat2value[metric, strategy] = value\n",
    "        \n",
    "        # Bar positions for each Coordination strategy\n",
    "        x_positions = np.arange(len(strategies))\n",
    "        \n",
    "        # Plot bars\n",
    "        handles = []\n",
    "        if column_y1 is None:\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            if mode == 'aut_missions':\n",
    "                add_to_metstrat2value(column_y1, df_pos[column_y1])\n",
    "            handles += [ax.bar(x_positions, df_pos[column_y1], width=bar_width, label=column_y1, color=color_y1)[0]]\n",
    "            ax.set_xlabel('Coordination Strategy')\n",
    "            ax.set_ylabel(column_y1, color=color_y1)\n",
    "            ax.tick_params(axis='y', labelcolor=color_y1)\n",
    "            ax.set_ylim(0, y1_lim)\n",
    "        \n",
    "        # Create a secondary axis for the points\n",
    "        ax_right = ax.twinx()\n",
    "        \n",
    "        # Plot points\n",
    "        label2series = {str(formula): formula.apply(df_pos)\n",
    "                        for formula in formulas_y2}\n",
    "        for (label, series), color in zip(label2series.items(), colors_y2):\n",
    "            if mode == 'cmp':\n",
    "                add_to_metstrat2value(label, series)\n",
    "            handles.append(\n",
    "                ax_right.plot(\n",
    "                    x_positions, series, label=label, marker='o', linestyle='', color=color\n",
    "                )[0]\n",
    "            )\n",
    "        ax_right.tick_params(axis='y', labelcolor='black')\n",
    "        ax_right.set_ylim(0, y2_lim)\n",
    "        \n",
    "        # Add labels, grid, and title for each section\n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.set_xticklabels([strategy2label.get(s, s) for s in strategies], rotation=60, ha='right')\n",
    "        ax.set_title(f'Position {position}')\n",
    "        ax.grid(axis='y')\n",
    "        \n",
    "    fig.suptitle(title1, fontsize=16)\n",
    "    \n",
    "    labels = [str(x) for x in [column_y1, *formulas_y2] if x is not None]\n",
    "    fig.legend(handles=handles, labels=labels, ncol=len(handles), loc='upper right')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    filename_png = save_and_show(fig, f'{title1}: {title2}')\n",
    "    \n",
    "    #print(id(df))\n",
    "    #IPython.display.display(df)    \n",
    "    return filename_png, pos2metstrat2value\n",
    "\n",
    "\n",
    "def plot_all(df_map):\n",
    "    key2df = {}\n",
    "    for are_bridges in True, False:\n",
    "        for is_aut in None, True, False:\n",
    "            dfx = df_map[df_map['are_bridges'] == are_bridges]\n",
    "            #dfx = dfx[dfx['configuration'].isin(index_nonblocked.get_level_values('configuration'))]\n",
    "            if is_aut is None:\n",
    "                dfx = dfx.groupby(['Positions variant', 'Vehicle ID']).agg({\n",
    "                    **{\n",
    "                        col: same_value \n",
    "                        for col in dfx.columns \n",
    "                        if col.startswith('Linearization')\n",
    "                        and col not in ('Linearization', 'Linearization (non-normalized)')  # because old data is broken\n",
    "                    },\n",
    "                })\n",
    "            else:\n",
    "                dfx = dfx[dfx['Vehicle type'] == ('AutonomousVehicle' if is_aut else 'HumanDrivenVehicle')]\n",
    "                dfx = dfx.groupby(['Positions variant', 'Coordination strategy']).agg({\n",
    "                    **{col: 'sum' for col in dfx.columns},\n",
    "                    **{col: same_value for col in (\n",
    "                        'Positions variant', 'Coordination strategy', 'configuration',\n",
    "                        'probabilityForcingForHuman', 'isCanPassFirstActive', 'probabilitySlowingDownForHuman',\n",
    "                    ) if col in dfx.columns},\n",
    "                    **{col: 'max' for col in ('Vehicle ID', )},\n",
    "                })\n",
    "                \n",
    "            key2df[are_bridges, is_aut] = dfx          \n",
    "            \n",
    "    are_bridges_to_plotdicts = {}\n",
    "    for are_bridges in True, False:\n",
    "        filenames_png = [\n",
    "            plot_title(\n",
    "                key2df[are_bridges, True],\n",
    "                title2=f\"Map {I_MAP} ({'with' if are_bridges else 'without'} bridges)\",\n",
    "            )\n",
    "        ]\n",
    "        are_bridges_to_plotdicts[are_bridges] = plotdicts = []\n",
    "        \n",
    "        cols_lin = [\n",
    "            col \n",
    "            for col in df_map \n",
    "            if re.match(\n",
    "                r'''\n",
    "                Linearization \n",
    "                (?:\n",
    "                    # just \"Linearization\"\n",
    "                |   \n",
    "                    [ ]\n",
    "                    [ABCD]\n",
    "                    # normalized \n",
    "                | \n",
    "                    [ ]\n",
    "                    [CD]\n",
    "                    [ ]\n",
    "                    [(]non-normalized[)]\n",
    "                )$\n",
    "                ''', \n",
    "                col, \n",
    "                flags=re.VERBOSE,\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        modes = [\n",
    "            *cols_lin,\n",
    "            'aut_distance', \n",
    "            'aut_missions', \n",
    "            'hum', \n",
    "            'cmp',\n",
    "        ]\n",
    "        \n",
    "        for mode in modes:\n",
    "            is_aut = mode.startswith('aut_')\n",
    "            title2 = f\"Map {I_MAP} ({'with' if are_bridges else 'without'} bridges)\"\n",
    "            \n",
    "            filename_png, pos2metstrat2value = (\n",
    "                plot_lin(\n",
    "                    key2df[are_bridges, None],\n",
    "                    title2=title2,\n",
    "                    column=mode,\n",
    "                )\n",
    "                if mode.startswith('Linearization') else\n",
    "                plot_aut_hum(\n",
    "                    key2df[are_bridges, is_aut],\n",
    "                    title2=title2, \n",
    "                    dfs_y1=[dfx for (_, is_aut_dfx), dfx in key2df.items() if is_aut_dfx == is_aut],\n",
    "                    dfs_y2=[key2df[are_bridges, is_aut_dfx] for is_aut_dfx in ([is_aut] if mode == 'cmp' else [True, False])], \n",
    "                    mode=mode,\n",
    "                )\n",
    "            )\n",
    "        \n",
    "            filenames_png.append(filename_png)\n",
    "            plotdicts.append(pos2metstrat2value)\n",
    "            \n",
    "        #IPython.display.display(dfx)\n",
    "        filename_out_png = f'{DIRECTORY_IMAGES}/All: Map {I_MAP} (' + ('with' if are_bridges else 'without') + ' bridges).png'\n",
    "        subprocess.run(['convert', *filenames_png, '-append', filename_out_png], check=True)\n",
    "        #print(plotdicts)\n",
    "        \n",
    "    return merge_are_bridges_to_plotdicts(are_bridges_to_plotdicts)\n",
    "    \n",
    "        \n",
    "def merge_are_bridges_to_plotdicts(are_bridges_to_plotdicts):\n",
    "    merged_data = {}\n",
    "    for are_bridges, plotdicts in are_bridges_to_plotdicts.items():\n",
    "        for pos_dict in plotdicts:\n",
    "            if are_bridges not in merged_data:\n",
    "                merged_data[are_bridges] = {}\n",
    "            for pos, metric_strat_dict in pos_dict.items():\n",
    "                if pos not in merged_data[are_bridges]:\n",
    "                    merged_data[are_bridges][pos] = {}\n",
    "                merged_data[are_bridges][pos].update(metric_strat_dict)\n",
    "                \n",
    "    # Step 2: Extract all unique keys for indexing\n",
    "    all_are_bridges = sorted(merged_data.keys())\n",
    "    all_positions = sorted({pos for are_val in merged_data.values() for pos in are_val.keys()})\n",
    "    all_pairs = [pair \n",
    "                 for are_val in merged_data.values() \n",
    "                 for pos_val in are_val.values() \n",
    "                 for pair in pos_val.keys()]\n",
    "    \n",
    "    unique_metrics = list({m: None for (m, s) in all_pairs})\n",
    "    unique_strategies = list({s: None for (m, s) in all_pairs})\n",
    "    \n",
    "    # Step 3: Create MultiIndex for rows and columns\n",
    "    row_index = pd.MultiIndex.from_product([[I_MAP], all_are_bridges, all_positions], names=[\"map\", \"are_bridges\", \"position\"])\n",
    "    col_index = pd.MultiIndex.from_product([unique_metrics, unique_strategies], names=[\"metric\", \"strategy\"])\n",
    "    \n",
    "    # Step 4: Create the DataFrame\n",
    "    df = pd.DataFrame(index=row_index, columns=col_index)\n",
    "    \n",
    "    # Step 5: Fill the DataFrame\n",
    "    for are_val, pos_dict in merged_data.items():\n",
    "        for pos, metric_strat_dict in pos_dict.items():\n",
    "            for (m, s), val in metric_strat_dict.items():\n",
    "                df.loc[(I_MAP, are_val, pos), (m, s)] = val\n",
    "    \n",
    "    return df\n",
    "            \n",
    "\n",
    "df_plotdicts = plot_all(df_map)\n",
    "df_plotdicts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbcc2f280377d030",
   "metadata": {},
   "source": [
    "#IPython.display.display(IPython.display.HTML(df_plotdicts.to_html()))\n",
    "df_plotdicts.to_csv(f'{DIRECTORY_IMAGES}/df_plotdicts_map{I_MAP}.csv')\n",
    "print(df_plotdicts.columns)\n",
    "print(df_plotdicts.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be8ea8dc10a5b772",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2f38995406bfb3a",
   "metadata": {},
   "source": [
    "def show_maps(title, configurations, ncols): \n",
    "    nrows = max(1, (len(configurations) + ncols - 1) // ncols)\n",
    "    fig, axes_matrix = plt.subplots(nrows, ncols, figsize=(16, 9), squeeze=False)\n",
    "    #print(f'{title}: {nrows}x{ncols}')\n",
    "\n",
    "    axes = list(itertools.chain.from_iterable(axes_matrix))\n",
    "    axes_matrix: list[list[Axes]]\n",
    "    assert len(axes) >= len(configurations)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    for ax, configuration in zip(axes, configurations):\n",
    "        filename_screenshot = configuration_to_filename_screenshot[configuration]\n",
    "        image = plt.imread(filename_screenshot)\n",
    "        ax.imshow(image)\n",
    "        ax.title.set_text(f'Configuration:\\n{configuration}')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=16)    \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "    save_and_show(fig, title)\n",
    "    \n",
    "    \n",
    "for title, index in {'Non-blocked': index_nonblocked, 'Blocked': index_blocked}.items():\n",
    "    for are_bridges in True, False:\n",
    "        show_maps(f'{title}: Map {I_MAP} ({\"with\" if are_bridges else \"without\"} bridges)', \n",
    "                  index[index.get_level_values('are_bridges') == are_bridges].get_level_values('configuration'), \n",
    "                  4)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
